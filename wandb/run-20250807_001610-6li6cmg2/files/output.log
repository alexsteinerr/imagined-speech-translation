INFO:__main__:Using device: cuda
INFO:src.data.dataset:Tokenizer vocabulary size: 51271
INFO:src.data.dataset:Frontal region: 16 channels - ['FC5', 'F5', 'F7', 'F3', 'FC1', 'F1', 'AF3', 'Fz', 'FC2', 'F2', 'AF4', 'Fp2', 'F4', 'F6', 'F8', 'FC6']
INFO:src.data.dataset:Temporal region: 9 channels - ['T9', 'FT9', 'T7', 'TP7', 'FT8', 'T10', 'FT10', 'T8', 'TP8']
INFO:src.data.dataset:Central region: 11 channels - ['C5', 'C3', 'FC3', 'C1', 'CP1', 'Cz', 'CP2', 'C2', 'C4', 'FC4', 'C6']
INFO:src.data.dataset:Parietal region: 12 channels - ['P7', 'P5', 'CP3', 'P3', 'PO3', 'PO1', 'PO2', 'P4', 'PO4', 'P6', 'CP4', 'P8']
INFO:src.data.dataset:Total channels mapped: 48/125
INFO:src.data.dataset:Tokenizer validation passed. Key IDs: pad=0, eos=104, bos=101
Discovering data files...
INFO:src.data.dataset:Found 225 .pkl files
INFO:src.data.dataset:Built index for 29466 samples
Computing normalization parameters from sample...
INFO:src.data.dataset:Fitted scaler for frontal with 100 samples
INFO:src.data.dataset:Fitted scaler for temporal with 100 samples
INFO:src.data.dataset:Fitted scaler for central with 100 samples
INFO:src.data.dataset:Fitted scaler for parietal with 100 samples
Dataset initialized with 29466 samples
INFO:__main__:Dataset loaded: 29466 samples
INFO:__main__:Region channel counts: {'frontal': 16, 'temporal': 9, 'central': 11, 'parietal': 12}
C:\Users\Marco\anaconda3\Lib\site-packages\torch\nn\modules\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
INFO:src.models.bart_decoder:Loaded BART model with vocab_size: 51271
INFO:__main__:Data splits - Train: 23572, Val: 2946, Test: 2948
C:\Users\Marco\anaconda3\Lib\site-packages\transformers\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:absl:Using default tokenizer.
INFO:src.training.trainer:Enhanced trainer initialized with diversity_loss_weight=0.1
INFO:src.training.trainer:Starting enhanced training for 100 epochs...
INFO:src.training.trainer:Loss weights - Diversity: 0.1, Alignment: 0.05, Variance: 0.02
Training Epoch 1:   0%|                                                                                                                                                                | 0/5893 [00:00<?, ?it/s]C:\Users\Marco\anaconda3\Lib\site-packages\torch\nn\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:555.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|                                                                                                       | 1/5893 [00:02<3:19:39,  2.03s/it, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|                                                                                                       | 2/5893 [00:02<2:15:39,  1.38s/it, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|                                                                                                       | 3/5893 [00:03<1:55:55,  1.18s/it, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|                                                                                                       | 4/5893 [00:04<1:47:37,  1.10s/it, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|                                                                                                       | 5/5893 [00:05<1:43:42,  1.06s/it, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|                                                                                                       | 6/5893 [00:06<1:41:14,  1.03s/it, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|                                                                                                       | 7/5893 [00:07<1:36:20,  1.02it/s, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|▏                                                                                                      | 8/5893 [00:08<1:40:54,  1.03s/it, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|▏                                                                                                      | 9/5893 [00:09<1:38:24,  1.00s/it, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|▏                                                                                                     | 10/5893 [00:10<1:37:49,  1.00it/s, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|▏                                                                                                     | 11/5893 [00:11<1:38:33,  1.01s/it, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|▏                                                                                                     | 12/5893 [00:12<1:38:40,  1.01s/it, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|▏                                                                                                     | 13/5893 [00:13<1:39:37,  1.02s/it, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|▏                                                                                                     | 14/5893 [00:14<1:38:41,  1.01s/it, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|▎                                                                                                     | 15/5893 [00:15<1:37:33,  1.00it/s, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|▎                                                                                                     | 16/5893 [00:16<1:38:17,  1.00s/it, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|▎                                                                                                     | 17/5893 [00:17<1:37:39,  1.00it/s, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
Training Epoch 1:   0%|▎                                                                                                     | 18/5893 [00:18<1:37:11,  1.01it/s, loss=5.1040, lr=0.0e+00, div=0.846, var=0.968]ERROR:src.models.bart_decoder:Enhanced BARTDecoder forward pass failed: BartForConditionalGeneration.forward() got an unexpected keyword argument 'label_smoothing_factor'
